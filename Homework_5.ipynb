{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhXvNcsfaQy/F2Exr+PFcA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cgree136/D3/blob/main/Homework_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PROBLEM 1\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "\n",
        "# Given data\n",
        "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0]\n",
        "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
        "\n",
        "t_c = np.array(t_c)\n",
        "t_u = np.array(t_u)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(t_u, t_c, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape the input features to 2D arrays\n",
        "X_train = X_train.reshape(-1, 1)\n",
        "X_val = X_val.reshape(-1, 1)\n",
        "\n",
        "# Standardize the input features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "\n",
        "# Convert the data to TensorFlow tensors\n",
        "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
        "X_val = tf.convert_to_tensor(X_val, dtype=tf.float32)\n",
        "y_val = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
        "\n",
        "# Define the linear model\n",
        "def quadratic_model(t_u, w2, w1, b):\n",
        "    return w2 * t_u ** 2 + w1 * t_u + b\n",
        "\n",
        "# Function to create and train a linear regression model\n",
        "def train_quadratic_regression(X_train, y_train, X_val, y_val, optimizer, learning_rate, epochs):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Input(shape=(1,)),\n",
        "        tf.keras.layers.Dense(1, use_bias=True)\n",
        "    ])\n",
        "\n",
        "    # Custom loss function for the linear model\n",
        "    def custom_loss(y_true, y_pred):\n",
        "        return tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "\n",
        "    model.compile(optimizer=optimizer(learning_rate=learning_rate), loss=custom_loss)\n",
        "\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, verbose=0)\n",
        "    return model, history.history\n",
        "\n",
        "# Hyperparameters to explore\n",
        "learning_rates = [0.1, 0.01, 0.001, 0.0001]\n",
        "epochs = 5000\n",
        "report_interval = 500\n",
        "\n",
        "# Train models with different learning rates using both SGD and ADAM optimizers\n",
        "results = []\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for optimizer_name, optimizer in [('SGD', tf.optimizers.SGD), ('ADAM', tf.optimizers.Adam)]:\n",
        "        model, history = train_quadratic_regression(X_train, y_train, X_val, y_val, optimizer, lr, epochs)\n",
        "\n",
        "        # Print loss for every 500 epochs\n",
        "        for epoch in range(report_interval, epochs + 1, report_interval):\n",
        "            loss = history['loss'][epoch - 1]\n",
        "            val_loss = history['val_loss'][epoch - 1]\n",
        "            print(f\"Optimizer: {optimizer_name}, Learning Rate: {lr}, Epoch: {epoch}, Loss: {loss}, Validation Loss: {val_loss}\")\n",
        "\n",
        "        results.append((optimizer_name, lr, history['val_loss'][-1]))\n",
        "\n",
        "# Find the best model\n",
        "best_result = min(results, key=lambda x: x[2])\n",
        "best_optimizer, best_lr, best_val_loss = best_result\n",
        "print(f\"Best model: Optimizer = {best_optimizer}, Learning Rate = {best_lr}, Validation Loss = {best_val_loss}\")\n",
        "\n",
        "# Visualize the Linear model against the data\n",
        "t_range = np.linspace(min(t_u), max(t_u), 100)\n",
        "quadratic_model_preds = model.predict(scaler.transform(t_range.reshape(-1, 1)))\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(X_train, y_train, label='Training Data')\n",
        "plt.scatter(X_val, y_val, label='Validation Data', color='r')\n",
        "plt.plot(t_range, quadratic_model_preds, label='Linear Model', color='b')\n",
        "plt.xlabel('Temperature (t_u)')\n",
        "plt.ylabel('Temperature (t_c)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uM_CMQWT0kbn",
        "outputId": "98dd51ad-55e3-4699-e99d-4fbdf8166d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 500, Loss: 2.811594009399414, Validation Loss: 4.403770446777344\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 1000, Loss: 2.811593770980835, Validation Loss: 4.403770446777344\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 1500, Loss: 2.811593770980835, Validation Loss: 4.403770446777344\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 2000, Loss: 2.811593770980835, Validation Loss: 4.403770446777344\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 2500, Loss: 2.811593770980835, Validation Loss: 4.403770446777344\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 3000, Loss: 2.811593770980835, Validation Loss: 4.403770446777344\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 3500, Loss: 2.811593770980835, Validation Loss: 4.403770446777344\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 4000, Loss: 2.811593770980835, Validation Loss: 4.403770446777344\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 4500, Loss: 2.811593770980835, Validation Loss: 4.403770446777344\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 5000, Loss: 2.811593770980835, Validation Loss: 4.403770446777344\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 500, Loss: 2.811593770980835, Validation Loss: 4.4037556648254395\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 1000, Loss: 2.8115928173065186, Validation Loss: 4.403759956359863\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 1500, Loss: 2.8115944862365723, Validation Loss: 4.40376091003418\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 2000, Loss: 2.811594247817993, Validation Loss: 4.4037628173828125\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 2500, Loss: 2.8115944862365723, Validation Loss: 4.403764247894287\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 3000, Loss: 2.8115947246551514, Validation Loss: 4.403768062591553\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 3500, Loss: 2.811593770980835, Validation Loss: 4.403767108917236\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 4000, Loss: 2.811593770980835, Validation Loss: 4.40377140045166\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 4500, Loss: 2.8115930557250977, Validation Loss: 4.403772830963135\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 5000, Loss: 2.8115930557250977, Validation Loss: 4.403772830963135\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 500, Loss: 2.8115949630737305, Validation Loss: 4.402143478393555\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 1000, Loss: 2.811594009399414, Validation Loss: 4.4037041664123535\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 1500, Loss: 2.811594009399414, Validation Loss: 4.4037041664123535\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 2000, Loss: 2.811594247817993, Validation Loss: 4.4037041664123535\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 2500, Loss: 2.811594009399414, Validation Loss: 4.4037041664123535\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 3000, Loss: 2.811594247817993, Validation Loss: 4.4037041664123535\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 3500, Loss: 2.811594009399414, Validation Loss: 4.4037041664123535\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 4000, Loss: 2.811594247817993, Validation Loss: 4.4037041664123535\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 4500, Loss: 2.811594247817993, Validation Loss: 4.4037041664123535\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 5000, Loss: 2.811594247817993, Validation Loss: 4.4037041664123535\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 500, Loss: 67.7153091430664, Validation Loss: 21.425148010253906\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 1000, Loss: 19.308088302612305, Validation Loss: 2.723752975463867\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 1500, Loss: 5.8160624504089355, Validation Loss: 0.3148317337036133\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 2000, Loss: 3.140050172805786, Validation Loss: 2.4009482860565186\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 2500, Loss: 2.82893705368042, Validation Loss: 3.884077787399292\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 3000, Loss: 2.811946392059326, Validation Loss: 4.3275861740112305\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 3500, Loss: 2.811596632003784, Validation Loss: 4.397938251495361\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 4000, Loss: 2.811593532562256, Validation Loss: 4.403562545776367\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 4500, Loss: 2.8115932941436768, Validation Loss: 4.4035868644714355\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 5000, Loss: 2.8115947246551514, Validation Loss: 4.403629302978516\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 500, Loss: 34.03761291503906, Validation Loss: 5.039865493774414\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 1000, Loss: 7.029111862182617, Validation Loss: 1.0576616525650024\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 1500, Loss: 3.3812291622161865, Validation Loss: 2.690525770187378\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 2000, Loss: 2.8885326385498047, Validation Loss: 3.7088279724121094\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 2500, Loss: 2.8219847679138184, Validation Loss: 4.139576435089111\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 3000, Loss: 2.8129968643188477, Validation Loss: 4.305487155914307\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 3500, Loss: 2.811784029006958, Validation Loss: 4.367500305175781\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 4000, Loss: 2.811619758605957, Validation Loss: 4.390415668487549\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 4500, Loss: 2.8115973472595215, Validation Loss: 4.398815631866455\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 5000, Loss: 2.811594009399414, Validation Loss: 4.401863098144531\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 500, Loss: 201.96014404296875, Validation Loss: 69.26543426513672\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 1000, Loss: 183.28135681152344, Validation Loss: 61.997867584228516\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 1500, Loss: 165.8587646484375, Validation Loss: 55.24681091308594\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 2000, Loss: 149.5982208251953, Validation Loss: 48.97679138183594\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 2500, Loss: 134.42311096191406, Validation Loss: 43.158966064453125\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 3000, Loss: 120.27198791503906, Validation Loss: 37.770172119140625\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 3500, Loss: 107.09602355957031, Validation Loss: 32.79199981689453\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 4000, Loss: 94.85639953613281, Validation Loss: 28.209732055664062\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 4500, Loss: 83.5217514038086, Validation Loss: 24.011423110961914\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 5000, Loss: 73.06616973876953, Validation Loss: 20.187074661254883\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 500, Loss: 175.11788940429688, Validation Loss: 59.75901794433594\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 1000, Loss: 143.8812713623047, Validation Loss: 46.52262496948242\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 1500, Loss: 118.30734252929688, Validation Loss: 35.99043655395508\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 2000, Loss: 97.36953735351562, Validation Loss: 27.64327049255371\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 2500, Loss: 80.22754669189453, Validation Loss: 21.05878257751465\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 3000, Loss: 66.19316864013672, Validation Loss: 15.893662452697754\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 3500, Loss: 54.70295333862305, Validation Loss: 11.869102478027344\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 4000, Loss: 45.29579162597656, Validation Loss: 8.758944511413574\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 4500, Loss: 37.593994140625, Validation Loss: 6.379802703857422\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 5000, Loss: 31.288421630859375, Validation Loss: 4.583251953125\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 500, Loss: 247.12091064453125, Validation Loss: 79.46715545654297\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 1000, Loss: 244.92581176757812, Validation Loss: 78.64575958251953\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 1500, Loss: 242.7439727783203, Validation Loss: 77.82987213134766\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 2000, Loss: 240.57476806640625, Validation Loss: 77.01920318603516\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 2500, Loss: 238.4175262451172, Validation Loss: 76.21353149414062\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 3000, Loss: 236.271728515625, Validation Loss: 75.41268920898438\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 3500, Loss: 234.13694763183594, Validation Loss: 74.61649322509766\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 4000, Loss: 232.0128173828125, Validation Loss: 73.82483673095703\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 4500, Loss: 229.89935302734375, Validation Loss: 73.0376968383789\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 5000, Loss: 227.79605102539062, Validation Loss: 72.25491333007812\n",
            "Best model: Optimizer = SGD, Learning Rate = 0.001, Validation Loss = 4.401863098144531\n",
            "4/4 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PROBLEM 2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the housing dataset\n",
        "data = pd.DataFrame({\n",
        "    'price': [13300000,\t12250000,\t12250000,\t12215000,\t11410000,\t10850000,\t10150000,\t10150000,\t9870000,\t9800000,\t9800000,\t9681000,\t9310000,\t9240000,\t9240000,\t9100000,\t9100000,\t8960000,\t8890000,\t8855000,\t8750000,\t8680000,\t8645000,\t8645000,\t8575000,\t8540000,\t8463000,\t8400000,\t8400000,\t8400000,\t8400000,\t8400000,\t8295000,\t8190000,\t8120000,\t8080940,\t8043000,\t7980000,\t7962500,\t7910000,\t7875000,\t7840000,\t7700000,\t7700000,\t7560000,\t7560000,\t7525000,\t7490000,\t7455000,\t7420000,\t7420000,\t7420000,\t7350000,\t7350000,\t7350000,\t7350000,\t7343000,\t7245000,\t7210000,\t7210000,\t7140000,\t7070000,\t7070000,\t7035000,\t7000000,\t6930000,\t6930000,\t6895000,\t6860000,\t6790000,\t6790000,\t6755000,\t6720000,\t6685000,\t6650000,\t6650000,\t6650000,\t6650000,\t6650000,\t6650000,\t6629000,\t6615000,\t6615000,\t6580000,\t6510000,\t6510000,\t6510000,\t6475000,\t6475000,\t6440000,\t6440000,\t6419000,\t6405000,\t6300000,\t6300000,\t6300000,\t6300000,\t6300000,\t6293000,\t6265000,\t6230000,\t6230000,\t6195000,\t6195000,\t6195000,\t6160000,\t6160000,\t6125000,\t6107500,\t6090000,\t6090000,\t6090000,\t6083000,\t6083000,\t6020000,\t6020000,\t6020000,\t5950000,\t5950000,\t5950000,\t5950000,\t5950000,\t5950000,\t5950000,\t5950000,\t5943000,\t5880000,\t5880000,\t5873000,\t5873000,\t5866000,\t5810000,\t5810000,\t5810000,\t5803000,\t5775000,\t5740000,\t5740000,\t5740000,\t5740000,\t5740000,\t5652500,\t5600000,\t5600000,\t5600000,\t5600000,\t5600000,\t5600000,\t5600000,\t5600000,\t5600000,\t5565000,\t5565000,\t5530000,\t5530000,\t5530000,\t5523000,\t5495000,\t5495000,\t5460000,\t5460000,\t5460000,\t5460000,\t5425000,\t5390000,\t5383000,\t5320000,\t5285000,\t5250000,\t5250000,\t5250000,\t5250000,\t5250000,\t5250000,\t5250000,\t5250000,\t5250000,\t5243000,\t5229000,\t5215000,\t5215000,\t5215000,\t5145000,\t5145000,\t5110000,\t5110000,\t5110000,\t5110000,\t5075000,\t5040000,\t5040000,\t5040000,\t5040000,\t5033000,\t5005000,\t4970000,\t4970000,\t4956000,\t4935000,\t4907000,\t4900000,\t4900000,\t4900000,\t4900000,\t4900000,\t4900000,\t4900000,\t4900000,\t4900000,\t4900000,\t4900000,\t4900000,\t4893000,\t4893000,\t4865000,\t4830000,\t4830000,\t4830000,\t4830000,\t4795000,\t4795000,\t4767000,\t4760000,\t4760000,\t4760000,\t4753000,\t4690000,\t4690000,\t4690000,\t4690000,\t4690000,\t4690000,\t4655000,\t4620000,\t4620000,\t4620000,\t4620000,\t4620000,\t4613000,\t4585000,\t4585000,\t4550000,\t4550000,\t4550000,\t4550000,\t4550000,\t4550000,\t4550000,\t4543000,\t4543000,\t4515000,\t4515000,\t4515000,\t4515000,\t4480000,\t4480000,\t4480000,\t4480000,\t4480000,\t4473000,\t4473000,\t4473000,\t4445000,\t4410000,\t4410000,\t4403000,\t4403000,\t4403000,\t4382000,\t4375000,\t4340000,\t4340000,\t4340000,\t4340000,\t4340000,\t4319000,\t4305000,\t4305000,\t4277000,\t4270000,\t4270000,\t4270000,\t4270000,\t4270000,\t4270000,\t4235000,\t4235000,\t4200000,\t4200000,\t4200000,\t4200000,\t4200000,\t4200000,\t4200000,\t4200000,\t4200000,\t4200000,\t4200000,\t4200000,\t4200000,\t4200000,\t4200000,\t4200000,\t4200000,\t4193000,\t4193000,\t4165000,\t4165000,\t4165000,\t4130000,\t4130000,\t4123000,\t4098500,\t4095000,\t4095000,\t4095000,\t4060000,\t4060000,\t4060000,\t4060000,\t4060000,\t4025000,\t4025000,\t4025000,\t4007500,\t4007500,\t3990000,\t3990000,\t3990000,\t3990000,\t3990000,\t3920000,\t3920000,\t3920000,\t3920000,\t3920000,\t3920000,\t3920000,\t3885000,\t3885000,\t3850000,\t3850000,\t3850000,\t3850000,\t3850000,\t3850000,\t3850000,\t3836000,\t3815000,\t3780000,\t3780000,\t3780000,\t3780000,\t3780000,\t3780000,\t3773000,\t3773000,\t3773000,\t3745000,\t3710000,\t3710000,\t3710000,\t3710000,\t3710000,\t3703000,\t3703000,\t3675000,\t3675000,\t3675000,\t3675000,\t3640000,\t3640000,\t3640000,\t3640000,\t3640000,\t3640000,\t3640000,\t3640000,\t3640000,\t3633000,\t3605000,\t3605000,\t3570000,\t3570000,\t3570000,\t3570000,\t3535000,\t3500000,\t3500000,\t3500000,\t3500000,\t3500000,\t3500000,\t3500000,\t3500000,\t3500000,\t3500000,\t3500000,\t3500000,\t3500000,\t3500000,\t3500000,\t3500000,\t3500000,\t3493000,\t3465000,\t3465000,\t3465000,\t3430000,\t3430000,\t3430000,\t3430000,\t3430000,\t3430000,\t3423000,\t3395000,\t3395000,\t3395000,\t3360000,\t3360000,\t3360000,\t3360000,\t3360000,\t3360000,\t3360000,\t3360000,\t3353000,\t3332000,\t3325000,\t3325000,\t3290000,\t3290000,\t3290000,\t3290000,\t3290000,\t3290000,\t3290000,\t3290000,\t3255000,\t3255000,\t3234000,\t3220000,\t3220000,\t3220000,\t3220000,\t3150000,\t3150000,\t3150000,\t3150000,\t3150000,\t3150000,\t3150000,\t3150000,\t3150000,\t3143000,\t3129000,\t3118850,\t3115000,\t3115000,\t3115000,\t3087000,\t3080000,\t3080000,\t3080000,\t3080000,\t3045000,\t3010000,\t3010000,\t3010000,\t3010000,\t3010000,\t3010000,\t3010000,\t3003000,\t2975000,\t2961000,\t2940000,\t2940000,\t2940000,\t2940000,\t2940000,\t2940000,\t2940000,\t2940000,\t2870000,\t2870000,\t2870000,\t2870000,\t2852500,\t2835000,\t2835000,\t2835000,\t2800000,\t2800000,\t2730000,\t2730000,\t2695000,\t2660000,\t2660000,\t2660000,\t2660000,\t2660000,\t2660000,\t2660000,\t2653000,\t2653000,\t2604000,\t2590000,\t2590000,\t2590000,\t2520000,\t2520000,\t2520000,\t2485000,\t2485000,\t2450000,\t2450000,\t2450000,\t2450000,\t2450000,\t2450000,\t2408000,\t2380000,\t2380000,\t2380000,\t2345000,\t2310000,\t2275000,\t2275000,\t2275000,\t2240000,\t2233000,\t2135000,\t2100000,\t2100000,\t2100000,\t1960000,\t1890000,\t1890000,\t1855000,\t1820000,\t1767150,\t1750000,\t1750000,\t1750000],\n",
        "    'area': [7420,\t8960,\t9960,\t7500,\t7420,\t7500,\t8580,\t16200,\t8100,\t5750,\t13200,\t6000,\t6550,\t3500,\t7800,\t6000,\t6600,\t8500,\t4600,\t6420,\t4320,\t7155,\t8050,\t4560,\t8800,\t6540,\t6000,\t8875,\t7950,\t5500,\t7475,\t7000,\t4880,\t5960,\t6840,\t7000,\t7482,\t9000,\t6000,\t6000,\t6550,\t6360,\t6480,\t6000,\t6000,\t6000,\t6000,\t6600,\t4300,\t7440,\t7440,\t6325,\t6000,\t5150,\t6000,\t6000,\t11440,\t9000,\t7680,\t6000,\t6000,\t8880,\t6240,\t6360,\t11175,\t8880,\t13200,\t7700,\t6000,\t12090,\t4000,\t6000,\t5020,\t6600,\t4040,\t4260,\t6420,\t6500,\t5700,\t6000,\t6000,\t4000,\t10500,\t6000,\t3760,\t8250,\t6670,\t3960,\t7410,\t8580,\t5000,\t6750,\t4800,\t7200,\t6000,\t4100,\t9000,\t6400,\t6600,\t6000,\t6600,\t5500,\t5500,\t6350,\t5500,\t4500,\t5450,\t6420,\t3240,\t6615,\t6600,\t8372,\t4300,\t9620,\t6800,\t8000,\t6900,\t3700,\t6420,\t7020,\t6540,\t7231,\t6254,\t7320,\t6525,\t15600,\t7160,\t6500,\t5500,\t11460,\t4800,\t5828,\t5200,\t4800,\t7000,\t6000,\t5400,\t4640,\t5000,\t6360,\t5800,\t6660,\t10500,\t4800,\t4700,\t5000,\t10500,\t5500,\t6360,\t6600,\t5136,\t4400,\t5400,\t3300,\t3650,\t6100,\t6900,\t2817,\t7980,\t3150,\t6210,\t6100,\t6600,\t6825,\t6710,\t6450,\t7800,\t4600,\t4260,\t6540,\t5500,\t10269,\t8400,\t5300,\t3800,\t9800,\t8520,\t6050,\t7085,\t3180,\t4500,\t7200,\t3410,\t7980,\t3000,\t3000,\t11410,\t6100,\t5720,\t3540,\t7600,\t10700,\t6600,\t4800,\t8150,\t4410,\t7686,\t2800,\t5948,\t4200,\t4520,\t4095,\t4120,\t5400,\t4770,\t6300,\t5800,\t3000,\t2970,\t6720,\t4646,\t12900,\t3420,\t4995,\t4350,\t4160,\t6040,\t6862,\t4815,\t7000,\t8100,\t3420,\t9166,\t6321,\t10240,\t6440,\t5170,\t6000,\t3630,\t9667,\t5400,\t4320,\t3745,\t4160,\t3880,\t5680,\t2870,\t5010,\t4510,\t4000,\t3840,\t3760,\t3640,\t2550,\t5320,\t5360,\t3520,\t8400,\t4100,\t4990,\t3510,\t3450,\t9860,\t3520,\t4510,\t5885,\t4000,\t8250,\t4040,\t6360,\t3162,\t3510,\t3750,\t3968,\t4900,\t2880,\t4880,\t4920,\t4950,\t3900,\t4500,\t1905,\t4075,\t3500,\t6450,\t4032,\t4400,\t10360,\t3400,\t6360,\t6360,\t4500,\t2175,\t4360,\t7770,\t6650,\t2787,\t5500,\t5040,\t5850,\t2610,\t2953,\t2747,\t4410,\t4000,\t2325,\t4600,\t3640,\t5800,\t7000,\t4079,\t3520,\t2145,\t4500,\t8250,\t3450,\t4840,\t4080,\t4046,\t4632,\t5985,\t6060,\t3600,\t3680,\t4040,\t5600,\t5900,\t4992,\t4340,\t3000,\t4320,\t3630,\t3460,\t5400,\t4500,\t3460,\t4100,\t6480,\t4500,\t3960,\t4050,\t7260,\t5500,\t3000,\t3290,\t3816,\t8080,\t2145,\t3780,\t3180,\t5300,\t3180,\t7152,\t4080,\t3850,\t2015,\t2176,\t3350,\t3150,\t4820,\t3420,\t3600,\t5830,\t2856,\t8400,\t8250,\t2520,\t6930,\t3480,\t3600,\t4040,\t6020,\t4050,\t3584,\t3120,\t5450,\t3630,\t3630,\t5640,\t3600,\t4280,\t3570,\t3180,\t3000,\t3520,\t5960,\t4130,\t2850,\t2275,\t3520,\t4500,\t4000,\t3150,\t4500,\t4500,\t3640,\t3850,\t4240,\t3650,\t4600,\t2135,\t3036,\t3990,\t7424,\t3480,\t3600,\t3640,\t5900,\t3120,\t7350,\t3512,\t9500,\t5880,\t12944,\t4900,\t3060,\t5320,\t2145,\t4000,\t3185,\t3850,\t2145,\t2610,\t1950,\t4040,\t4785,\t3450,\t3640,\t3500,\t4960,\t4120,\t4750,\t3720,\t3750,\t3100,\t3185,\t2700,\t2145,\t4040,\t4775,\t2500,\t3180,\t6060,\t3480,\t3792,\t4040,\t2145,\t5880,\t4500,\t3930,\t3640,\t4370,\t2684,\t4320,\t3120,\t3450,\t3986,\t3500,\t4095,\t1650,\t3450,\t6750,\t9000,\t3069,\t4500,\t5495,\t2398,\t3000,\t3850,\t3500,\t8100,\t4960,\t2160,\t3090,\t4500,\t3800,\t3090,\t3240,\t2835,\t4600,\t5076,\t3750,\t3630,\t8050,\t4352,\t3000,\t5850,\t4960,\t3600,\t3660,\t3480,\t2700,\t3150,\t6615,\t3040,\t3630,\t6000,\t5400,\t5200,\t3300,\t4350,\t2640,\t2650,\t3960,\t6800,\t4000,\t4000,\t3934,\t2000,\t3630,\t2800,\t2430,\t3480,\t4000,\t3185,\t4000,\t2910,\t3600,\t4400,\t3600,\t2880,\t3180,\t3000,\t4400,\t3000,\t3210,\t3240,\t3000,\t3500,\t4840,\t7700,\t3635,\t2475,\t2787,\t3264,\t3640,\t3180,\t1836,\t3970,\t3970,\t1950,\t5300,\t3000,\t2400,\t3000,\t3360,\t3420,\t1700,\t3649,\t2990,\t3000,\t2400,\t3620,\t2910,\t3850],\n",
        "    'bedrooms': [4,\t4,\t3,\t4,\t4,\t3,\t4,\t5,\t4,\t3,\t3,\t4,\t4,\t4,\t3,\t4,\t4,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t4,\t3,\t3,\t5,\t4,\t3,\t3,\t4,\t3,\t5,\t3,\t3,\t4,\t3,\t4,\t3,\t3,\t3,\t4,\t4,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t4,\t3,\t3,\t3,\t4,\t4,\t4,\t3,\t3,\t2,\t4,\t4,\t3,\t3,\t2,\t3,\t3,\t4,\t3,\t4,\t3,\t2,\t3,\t4,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t5,\t3,\t2,\t3,\t3,\t4,\t3,\t3,\t3,\t3,\t4,\t3,\t3,\t3,\t3,\t3,\t3,\t4,\t3,\t4,\t4,\t3,\t3,\t6,\t3,\t2,\t3,\t3,\t4,\t3,\t3,\t3,\t3,\t4,\t4,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t4,\t3,\t3,\t3,\t3,\t4,\t4,\t3,\t3,\t3,\t4,\t4,\t5,\t4,\t3,\t2,\t3,\t3,\t4,\t3,\t4,\t5,\t3,\t3,\t3,\t3,\t4,\t3,\t3,\t4,\t3,\t4,\t3,\t3,\t3,\t3,\t2,\t4,\t4,\t3,\t3,\t3,\t4,\t3,\t4,\t3,\t3,\t3,\t3,\t4,\t3,\t3,\t3,\t3,\t3,\t2,\t3,\t2,\t2,\t4,\t3,\t3,\t2,\t3,\t4,\t3,\t3,\t3,\t3,\t3,\t3,\t2,\t4,\t3,\t3,\t2,\t3,\t3,\t3,\t3,\t3,\t4,\t4,\t2,\t3,\t3,\t3,\t2,\t3,\t4,\t4,\t2,\t3,\t2,\t2,\t3,\t2,\t3,\t4,\t2,\t3,\t3,\t3,\t3,\t3,\t2,\t3,\t4,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t4,\t2,\t4,\t3,\t3,\t3,\t2,\t4,\t2,\t3,\t3,\t3,\t2,\t3,\t3,\t2,\t3,\t2,\t3,\t3,\t3,\t4,\t3,\t3,\t5,\t3,\t4,\t4,\t2,\t2,\t2,\t3,\t2,\t2,\t2,\t3,\t4,\t2,\t3,\t3,\t3,\t3,\t2,\t4,\t3,\t4,\t2,\t4,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t4,\t3,\t2,\t3,\t3,\t2,\t2,\t4,\t3,\t3,\t4,\t3,\t3,\t3,\t3,\t3,\t4,\t4,\t3,\t3,\t3,\t2,\t3,\t4,\t3,\t2,\t2,\t3,\t4,\t2,\t4,\t5,\t2,\t3,\t2,\t2,\t3,\t2,\t3,\t2,\t3,\t2,\t2,\t2,\t3,\t2,\t3,\t5,\t4,\t2,\t3,\t2,\t3,\t2,\t2,\t3,\t2,\t2,\t2,\t2,\t2,\t2,\t3,\t3,\t2,\t2,\t3,\t3,\t3,\t3,\t3,\t2,\t2,\t3,\t4,\t2,\t2,\t3,\t3,\t3,\t4,\t3,\t3,\t3,\t3,\t3,\t6,\t2,\t2,\t3,\t2,\t2,\t3,\t2,\t3,\t3,\t3,\t2,\t3,\t2,\t2,\t3,\t3,\t3,\t3,\t2,\t3,\t3,\t2,\t4,\t4,\t2,\t2,\t2,\t3,\t3,\t2,\t3,\t3,\t2,\t4,\t2,\t4,\t3,\t4,\t4,\t2,\t3,\t3,\t2,\t2,\t4,\t3,\t2,\t3,\t3,\t1,\t2,\t2,\t2,\t3,\t3,\t2,\t3,\t2,\t3,\t3,\t3,\t3,\t3,\t2,\t2,\t2,\t3,\t2,\t2,\t2,\t3,\t3,\t2,\t2,\t3,\t3,\t4,\t2,\t4,\t2,\t3,\t2,\t3,\t4,\t3,\t2,\t3,\t3,\t2,\t2,\t2,\t4,\t4,\t3,\t3,\t2,\t3,\t3,\t2,\t3,\t2,\t2,\t2,\t3,\t3,\t3,\t2,\t3,\t2,\t3,\t2,\t2,\t2,\t2,\t3,\t3,\t2,\t3,\t3,\t3,\t2,\t2,\t2,\t2,\t2,\t2,\t3,\t4,\t2,\t2,\t2,\t2,\t1,\t3,\t3,\t3,\t2,\t3,\t4,\t2,\t5,\t3,\t2,\t2,\t2,\t3,\t2,\t3,\t3],\n",
        "    'bathrooms': [2,\t4,\t2,\t2,\t1,\t3,\t3,\t3,\t1,\t2,\t1,\t3,\t2,\t2,\t2,\t1,\t2,\t2,\t2,\t2,\t1,\t2,\t1,\t2,\t2,\t2,\t2,\t1,\t2,\t2,\t2,\t1,\t2,\t3,\t1,\t2,\t2,\t2,\t1,\t2,\t1,\t2,\t2,\t2,\t2,\t2,\t2,\t1,\t2,\t2,\t2,\t1,\t2,\t2,\t2,\t1,\t1,\t2,\t2,\t2,\t2,\t1,\t2,\t2,\t1,\t2,\t1,\t2,\t1,\t2,\t2,\t2,\t1,\t2,\t1,\t2,\t2,\t2,\t1,\t2,\t1,\t2,\t2,\t2,\t1,\t2,\t1,\t1,\t1,\t3,\t1,\t1,\t2,\t2,\t2,\t2,\t1,\t1,\t2,\t1,\t2,\t1,\t2,\t2,\t2,\t1,\t2,\t1,\t1,\t2,\t1,\t1,\t2,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t2,\t2,\t2,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t2,\t1,\t1,\t1,\t2,\t2,\t2,\t2,\t1,\t1,\t1,\t2,\t1,\t2,\t1,\t1,\t1,\t3,\t2,\t2,\t1,\t2,\t1,\t2,\t1,\t1,\t2,\t1,\t2,\t2,\t1,\t2,\t1,\t2,\t2,\t1,\t1,\t2,\t1,\t2,\t1,\t1,\t1,\t2,\t2,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t3,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t3,\t1,\t2,\t1,\t2,\t1,\t2,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t2,\t2,\t1,\t1,\t1,\t2,\t2,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t2,\t2,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t2,\t2,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t3,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1],\n",
        "    'stories': [3,\t4,\t2,\t2,\t2,\t1,\t4,\t2,\t2,\t4,\t2,\t2,\t2,\t2,\t2,\t2,\t2,\t4,\t2,\t2,\t2,\t1,\t1,\t2,\t2,\t2,\t4,\t1,\t2,\t2,\t4,\t4,\t2,\t2,\t2,\t4,\t3,\t4,\t4,\t4,\t2,\t4,\t4,\t4,\t4,\t3,\t4,\t4,\t2,\t1,\t4,\t4,\t4,\t4,\t2,\t2,\t2,\t4,\t4,\t4,\t2,\t1,\t2,\t3,\t1,\t2,\t1,\t1,\t1,\t2,\t2,\t4,\t4,\t4,\t2,\t2,\t3,\t3,\t1,\t3,\t2,\t2,\t1,\t4,\t2,\t3,\t3,\t1,\t1,\t2,\t2,\t1,\t4,\t1,\t4,\t3,\t1,\t1,\t3,\t3,\t1,\t3,\t4,\t3,\t1,\t4,\t1,\t3,\t3,\t2,\t1,\t3,\t2,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t2,\t1,\t2,\t4,\t1,\t1,\t3,\t3,\t3,\t1,\t4,\t3,\t3,\t1,\t4,\t2,\t2,\t3,\t1,\t4,\t2,\t2,\t3,\t2,\t4,\t1,\t2,\t3,\t1,\t2,\t2,\t2,\t2,\t2,\t1,\t1,\t2,\t1,\t1,\t4,\t3,\t2,\t1,\t2,\t1,\t1,\t1,\t2,\t2,\t1,\t1,\t2,\t1,\t2,\t2,\t1,\t1,\t1,\t2,\t1,\t2,\t2,\t1,\t2,\t2,\t2,\t1,\t2,\t1,\t2,\t2,\t1,\t1,\t1,\t2,\t1,\t2,\t2,\t2,\t2,\t2,\t1,\t2,\t1,\t1,\t1,\t2,\t3,\t1,\t2,\t1,\t2,\t1,\t1,\t3,\t1,\t2,\t1,\t2,\t4,\t2,\t1,\t2,\t1,\t1,\t4,\t1,\t2,\t2,\t2,\t1,\t2,\t1,\t2,\t2,\t2,\t2,\t2,\t2,\t2,\t1,\t2,\t2,\t2,\t2,\t1,\t4,\t1,\t2,\t3,\t2,\t1,\t2,\t2,\t1,\t2,\t1,\t2,\t1,\t2,\t2,\t1,\t2,\t2,\t2,\t1,\t2,\t2,\t2,\t3,\t2,\t1,\t2,\t2,\t1,\t1,\t1,\t2,\t1,\t2,\t1,\t2,\t2,\t1,\t2,\t1,\t2,\t2,\t1,\t2,\t2,\t2,\t1,\t2,\t2,\t2,\t2,\t1,\t1,\t3,\t2,\t3,\t1,\t1,\t2,\t2,\t2,\t2,\t2,\t1,\t1,\t1,\t2,\t2,\t1,\t2,\t2,\t1,\t3,\t2,\t2,\t1,\t1,\t2,\t2,\t1,\t2,\t2,\t2,\t2,\t1,\t2,\t2,\t1,\t1,\t1,\t1,\t2,\t2,\t2,\t1,\t2,\t1,\t1,\t2,\t2,\t2,\t1,\t2,\t2,\t1,\t1,\t3,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t2,\t2,\t1,\t2,\t2,\t2,\t3,\t1,\t1,\t1,\t2,\t2,\t1,\t1,\t1,\t2,\t2,\t2,\t2,\t2,\t2,\t1,\t1,\t2,\t1,\t1,\t2,\t1,\t1,\t2,\t1,\t1,\t2,\t1,\t1,\t3,\t1,\t1,\t1,\t3,\t2,\t2,\t1,\t2,\t1,\t1,\t2,\t3,\t2,\t1,\t1,\t1,\t2,\t1,\t1,\t2,\t1,\t2,\t1,\t2,\t1,\t2,\t2,\t1,\t2,\t1,\t1,\t1,\t2,\t2,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t2,\t2,\t1,\t2,\t1,\t2,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t2,\t1,\t2,\t1,\t2,\t2,\t1,\t1,\t1,\t2,\t2,\t1,\t2,\t2,\t2,\t1,\t2,\t2,\t2,\t1,\t2,\t2,\t1,\t1,\t1,\t2,\t3,\t2,\t2,\t1,\t2,\t1,\t1,\t2,\t1,\t1,\t2,\t2,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t2,\t1,\t1,\t2,\t2,\t2,\t2,\t1,\t1,\t1,\t2,\t1,\t1,\t2,\t2,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t2,\t2,\t1,\t2,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t2],\n",
        "    'parking': [2,\t3,\t2,\t3,\t2,\t2,\t2,\t0,\t2,\t1,\t2,\t2,\t1,\t2,\t0,\t2,\t1,\t2,\t2,\t1,\t2,\t2,\t1,\t1,\t2,\t2,\t0,\t1,\t2,\t1,\t2,\t2,\t1,\t1,\t1,\t2,\t1,\t2,\t2,\t1,\t0,\t0,\t2,\t2,\t1,\t0,\t1,\t3,\t1,\t0,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t2,\t1,\t2,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t2,\t0,\t1,\t1,\t1,\t0,\t2,\t0,\t0,\t2,\t2,\t2,\t0,\t2,\t0,\t3,\t1,\t2,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t2,\t0,\t0,\t0,\t1,\t1,\t2,\t2,\t0,\t2,\t2,\t2,\t0,\t0,\t0,\t2,\t2,\t0,\t1,\t0,\t1,\t2,\t2,\t0,\t1,\t2,\t0,\t0,\t0,\t0,\t2,\t0,\t2,\t1,\t0,\t2,\t0,\t1,\t1,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t2,\t0,\t0,\t2,\t2,\t0,\t1,\t2,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t2,\t2,\t0,\t0,\t0,\t1,\t2,\t0,\t1,\t2,\t2,\t0,\t2,\t2,\t2,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t2,\t0,\t0,\t0,\t0,\t2,\t0,\t1,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t2,\t0,\t0,\t0,\t0,\t2,\t2,\t2,\t0,\t0,\t0,\t2,\t2,\t0,\t0,\t2,\t0,\t2,\t1,\t2,\t3,\t0,\t1,\t2,\t1,\t0,\t0,\t0,\t0,\t2,\t1,\t0,\t0,\t0,\t1,\t1,\t2,\t0,\t0,\t0,\t2,\t0,\t3,\t0,\t0,\t0,\t1,\t0,\t0,\t2,\t1,\t2,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t2,\t1,\t0,\t0,\t1,\t0,\t2,\t2,\t0,\t0,\t1,\t1,\t2,\t0,\t0,\t2,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t2,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t2,\t3,\t0,\t0,\t1,\t0,\t3,\t1,\t1,\t2,\t1,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t1,\t2,\t0,\t2,\t2,\t2,\t1,\t3,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t3,\t0,\t0,\t1,\t2,\t2,\t0,\t0,\t0,\t0,\t2,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t2,\t0,\t1,\t2,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t2,\t0,\t0,\t0,\t0,\t0,\t2,\t0,\t0,\t2,\t0,\t0,\t0,\t2,\t0,\t0,\t2,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t3,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t2,\t0,\t0,\t0,\t0,\t0,\t1,\t2,\t0,\t2,\t0,\t0,\t0,\t0,\t0,\t0,\t2,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t2,\t0,\t0,\t0,\t2,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t2,\t0,\t0,\t0,\t0,\t3,\t0,\t1,\t0,\t1,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t2,\t0,\t0,\t0,\t0],\n",
        "    'mainroad': [1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t0,\t1,\t0,\t1,\t0,\t1,\t1,\t1,\t0,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t0,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t0,\t1,\t1,\t0,\t1,\t0,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t1,\t1,\t0,\t1,\t0,\t1,\t0,\t1],\n",
        "    'guestroom': [0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t1,\t1,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t1,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0],\n",
        "    'basement': [0,\t0,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t1,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t0,\t1,\t0,\t1,\t0,\t1,\t0,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t0,\t1,\t1,\t0,\t1,\t0,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t1,\t1,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t1,\t0,\t1,\t0,\t1,\t0,\t1,\t1,\t1,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0],\n",
        "    'hotwaterheating': [0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0],\n",
        "    'aircondition': [1,\t1,\t0,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t0,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t1,\t0,\t0,\t1,\t0,\t1,\t0,\t1,\t1,\t0,\t1,\t0,\t1,\t1,\t0,\t1,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t1,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t1,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0],\n",
        "    'prefarea': [1,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t1,\t0,\t1,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t0,\t1,\t1,\t1,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0],\n",
        "    })\n",
        "\n",
        "# Define input features and target variable\n",
        "X = data[['area', 'bedrooms', 'bathrooms', 'stories', 'parking']].values\n",
        "y = data['price'].values\n",
        "\n",
        "# Split the data into training and validation sets (80% - 20% split)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the input features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "\n",
        "# Function to create and train a linear regression model\n",
        "def train_linear_regression(X_train, y_train, X_val, y_val, optimizer, learning_rate, epochs):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Input(shape=(5,)),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer=optimizer(learning_rate=learning_rate), loss='mean_squared_error')\n",
        "\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, verbose=0)\n",
        "    return model, history.history\n",
        "\n",
        "# Hyperparameters to explore\n",
        "learning_rates = [0.1, 0.01, 0.001, 0.0001]\n",
        "epochs = 5500\n",
        "report_interval = 500\n",
        "\n",
        "# Train models with different learning rates using both SGD and ADAM optimizers\n",
        "results = []\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for optimizer_name, optimizer in [('SGD', tf.optimizers.SGD), ('ADAM', tf.optimizers.Adam)]:\n",
        "        model, history = train_linear_regression(X_train, y_train, X_val, y_val, optimizer, lr, epochs)\n",
        "\n",
        "        # Print loss and validation accuracy for every 500 epochs\n",
        "        for epoch in range(500, epochs, report_interval):\n",
        "            loss = history['loss'][epoch]\n",
        "            val_loss = history['val_loss'][epoch]\n",
        "            print(f\"Optimizer: {optimizer_name}, Learning Rate: {lr}, Epoch: {epoch}, Loss: {loss}, Validation Loss: {val_loss}\")\n",
        "\n",
        "        results.append((optimizer_name, lr, history['val_loss'][-1]))\n",
        "\n",
        "# Find the best model\n",
        "best_result = min(results, key=lambda x: x[2])\n",
        "best_optimizer, best_lr, best_val_loss = best_result\n",
        "print(f\"Best model: Optimizer = {best_optimizer}, Learning Rate = {best_lr}, Validation Loss = {best_val_loss}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pobhdtMjmfxt",
        "outputId": "20ec4153-aad0-4f31-e55c-119a4b516d0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 500, Loss: 1400818761728.0, Validation Loss: 2299734261760.0\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 1000, Loss: 1406935367680.0, Validation Loss: 2311866286080.0\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 1500, Loss: 1403577696256.0, Validation Loss: 2289901240320.0\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 2000, Loss: 1392369336320.0, Validation Loss: 2363952201728.0\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 2500, Loss: 1407575523328.0, Validation Loss: 2241885372416.0\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 3000, Loss: 1416885436416.0, Validation Loss: 2664379187200.0\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 3500, Loss: 1394195169280.0, Validation Loss: 2253211828224.0\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 4000, Loss: 1397987213312.0, Validation Loss: 2254366834688.0\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 4500, Loss: 1412294639616.0, Validation Loss: 2321681219584.0\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 5000, Loss: 1408365494272.0, Validation Loss: 2401134182400.0\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 500, Loss: 25224869314560.0, Validation Loss: 30116683972608.0\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 1000, Loss: 25214966562816.0, Validation Loss: 30103423680512.0\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 1500, Loss: 25205080588288.0, Validation Loss: 30090184359936.0\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 2000, Loss: 25195198808064.0, Validation Loss: 30076949233664.0\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 2500, Loss: 25185304444928.0, Validation Loss: 30063684747264.0\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 3000, Loss: 25175433150464.0, Validation Loss: 30050460106752.0\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 3500, Loss: 25165563953152.0, Validation Loss: 30037250146304.0\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 4000, Loss: 25155703144448.0, Validation Loss: 30024042283008.0\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 4500, Loss: 25145846530048.0, Validation Loss: 30010849099776.0\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 5000, Loss: 25135981527040.0, Validation Loss: 29997628653568.0\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 500, Loss: 1356197920768.0, Validation Loss: 2286209990656.0\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 1000, Loss: 1355274256384.0, Validation Loss: 2296259280896.0\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 1500, Loss: 1356932055040.0, Validation Loss: 2297586515968.0\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 2000, Loss: 1355534041088.0, Validation Loss: 2287130378240.0\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 2500, Loss: 1357674315776.0, Validation Loss: 2289421516800.0\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 3000, Loss: 1356518916096.0, Validation Loss: 2303050645504.0\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 3500, Loss: 1358065303552.0, Validation Loss: 2290537201664.0\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 4000, Loss: 1354900832256.0, Validation Loss: 2287609053184.0\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 4500, Loss: 1356214566912.0, Validation Loss: 2292058947584.0\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 5000, Loss: 1356723912704.0, Validation Loss: 2312106409984.0\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 500, Loss: 25233798987776.0, Validation Loss: 30128658710528.0\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 1000, Loss: 25232809132032.0, Validation Loss: 30127333310464.0\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 1500, Loss: 25231819276288.0, Validation Loss: 30126003716096.0\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 2000, Loss: 25230827323392.0, Validation Loss: 30124676218880.0\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 2500, Loss: 25229837467648.0, Validation Loss: 30123355013120.0\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 3000, Loss: 25228847611904.0, Validation Loss: 30122029613056.0\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 3500, Loss: 25227859853312.0, Validation Loss: 30120700018688.0\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 4000, Loss: 25226867900416.0, Validation Loss: 30119376715776.0\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 4500, Loss: 25225880141824.0, Validation Loss: 30118049218560.0\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 5000, Loss: 25224883994624.0, Validation Loss: 30116719624192.0\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 500, Loss: 1350627098624.0, Validation Loss: 2293159165952.0\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 1000, Loss: 1350544130048.0, Validation Loss: 2294785245184.0\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 1500, Loss: 1350675202048.0, Validation Loss: 2291466764288.0\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 2000, Loss: 1350411354112.0, Validation Loss: 2292491485184.0\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 2500, Loss: 1350561431552.0, Validation Loss: 2293588295680.0\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 3000, Loss: 1350666813440.0, Validation Loss: 2292860321792.0\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 3500, Loss: 1350548848640.0, Validation Loss: 2291161628672.0\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 4000, Loss: 1350596689920.0, Validation Loss: 2293557624832.0\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 4500, Loss: 1350500876288.0, Validation Loss: 2292796096512.0\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 5000, Loss: 1350482132992.0, Validation Loss: 2292687568896.0\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 500, Loss: 25234694471680.0, Validation Loss: 30129862475776.0\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 1000, Loss: 25234595905536.0, Validation Loss: 30129730355200.0\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 1500, Loss: 25234495242240.0, Validation Loss: 30129600331776.0\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 2000, Loss: 25234396676096.0, Validation Loss: 30129466114048.0\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 2500, Loss: 25234298109952.0, Validation Loss: 30129333993472.0\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 3000, Loss: 25234199543808.0, Validation Loss: 30129199775744.0\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 3500, Loss: 25234096783360.0, Validation Loss: 30129065558016.0\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 4000, Loss: 25233998217216.0, Validation Loss: 30128937631744.0\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 4500, Loss: 25233901748224.0, Validation Loss: 30128801316864.0\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 5000, Loss: 25233803182080.0, Validation Loss: 30128669196288.0\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 500, Loss: 2724477272064.0, Validation Loss: 4049872617472.0\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 1000, Loss: 1435731230720.0, Validation Loss: 2455756865536.0\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 1500, Loss: 1355753586688.0, Validation Loss: 2316872187904.0\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 2000, Loss: 1350513459200.0, Validation Loss: 2298241351680.0\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 2500, Loss: 1350107529216.0, Validation Loss: 2294447603712.0\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 3000, Loss: 1350068731904.0, Validation Loss: 2292876312576.0\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 3500, Loss: 1350074892288.0, Validation Loss: 2293070561280.0\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 4000, Loss: 1350061916160.0, Validation Loss: 2292974616576.0\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 4500, Loss: 1350056017920.0, Validation Loss: 2292302479360.0\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 5000, Loss: 1350062047232.0, Validation Loss: 2292880244736.0\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 500, Loss: 25234780454912.0, Validation Loss: 30129971527680.0\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 1000, Loss: 25234769969152.0, Validation Loss: 30129958944768.0\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 1500, Loss: 25234757386240.0, Validation Loss: 30129944264704.0\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 2000, Loss: 25234746900480.0, Validation Loss: 30129931681792.0\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 2500, Loss: 25234740609024.0, Validation Loss: 30129917001728.0\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 3000, Loss: 25234728026112.0, Validation Loss: 30129904418816.0\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 3500, Loss: 25234717540352.0, Validation Loss: 30129891835904.0\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 4000, Loss: 25234709151744.0, Validation Loss: 30129877155840.0\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 4500, Loss: 25234698665984.0, Validation Loss: 30129864572928.0\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 5000, Loss: 25234688180224.0, Validation Loss: 30129854087168.0\n",
            "Best model: Optimizer = SGD, Learning Rate = 0.01, Validation Loss = 2288377659392.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PROBLEM 3\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the housing dataset\n",
        "data = pd.DataFrame({\n",
        "    'price': [13300000,\t12250000,\t12250000,\t12215000,\t11410000,\t10850000,\t10150000,\t10150000,\t9870000,\t9800000,\t9800000,\t9681000,\t9310000,\t9240000,\t9240000,\t9100000,\t9100000,\t8960000,\t8890000,\t8855000,\t8750000,\t8680000,\t8645000,\t8645000,\t8575000,\t8540000,\t8463000,\t8400000,\t8400000,\t8400000,\t8400000,\t8400000,\t8295000,\t8190000,\t8120000,\t8080940,\t8043000,\t7980000,\t7962500,\t7910000,\t7875000,\t7840000,\t7700000,\t7700000,\t7560000,\t7560000,\t7525000,\t7490000,\t7455000,\t7420000,\t7420000,\t7420000,\t7350000,\t7350000,\t7350000,\t7350000,\t7343000,\t7245000,\t7210000,\t7210000,\t7140000,\t7070000,\t7070000,\t7035000,\t7000000,\t6930000,\t6930000,\t6895000,\t6860000,\t6790000,\t6790000,\t6755000,\t6720000,\t6685000,\t6650000,\t6650000,\t6650000,\t6650000,\t6650000,\t6650000,\t6629000,\t6615000,\t6615000,\t6580000,\t6510000,\t6510000,\t6510000,\t6475000,\t6475000,\t6440000,\t6440000,\t6419000,\t6405000,\t6300000,\t6300000,\t6300000,\t6300000,\t6300000,\t6293000,\t6265000,\t6230000,\t6230000,\t6195000,\t6195000,\t6195000,\t6160000,\t6160000,\t6125000,\t6107500,\t6090000,\t6090000,\t6090000,\t6083000,\t6083000,\t6020000,\t6020000,\t6020000,\t5950000,\t5950000,\t5950000,\t5950000,\t5950000,\t5950000,\t5950000,\t5950000,\t5943000,\t5880000,\t5880000,\t5873000,\t5873000,\t5866000,\t5810000,\t5810000,\t5810000,\t5803000,\t5775000,\t5740000,\t5740000,\t5740000,\t5740000,\t5740000,\t5652500,\t5600000,\t5600000,\t5600000,\t5600000,\t5600000,\t5600000,\t5600000,\t5600000,\t5600000,\t5565000,\t5565000,\t5530000,\t5530000,\t5530000,\t5523000,\t5495000,\t5495000,\t5460000,\t5460000,\t5460000,\t5460000,\t5425000,\t5390000,\t5383000,\t5320000,\t5285000,\t5250000,\t5250000,\t5250000,\t5250000,\t5250000,\t5250000,\t5250000,\t5250000,\t5250000,\t5243000,\t5229000,\t5215000,\t5215000,\t5215000,\t5145000,\t5145000,\t5110000,\t5110000,\t5110000,\t5110000,\t5075000,\t5040000,\t5040000,\t5040000,\t5040000,\t5033000,\t5005000,\t4970000,\t4970000,\t4956000,\t4935000,\t4907000,\t4900000,\t4900000,\t4900000,\t4900000,\t4900000,\t4900000,\t4900000,\t4900000,\t4900000,\t4900000,\t4900000,\t4900000,\t4893000,\t4893000,\t4865000,\t4830000,\t4830000,\t4830000,\t4830000,\t4795000,\t4795000,\t4767000,\t4760000,\t4760000,\t4760000,\t4753000,\t4690000,\t4690000,\t4690000,\t4690000,\t4690000,\t4690000,\t4655000,\t4620000,\t4620000,\t4620000,\t4620000,\t4620000,\t4613000,\t4585000,\t4585000,\t4550000,\t4550000,\t4550000,\t4550000,\t4550000,\t4550000,\t4550000,\t4543000,\t4543000,\t4515000,\t4515000,\t4515000,\t4515000,\t4480000,\t4480000,\t4480000,\t4480000,\t4480000,\t4473000,\t4473000,\t4473000,\t4445000,\t4410000,\t4410000,\t4403000,\t4403000,\t4403000,\t4382000,\t4375000,\t4340000,\t4340000,\t4340000,\t4340000,\t4340000,\t4319000,\t4305000,\t4305000,\t4277000,\t4270000,\t4270000,\t4270000,\t4270000,\t4270000,\t4270000,\t4235000,\t4235000,\t4200000,\t4200000,\t4200000,\t4200000,\t4200000,\t4200000,\t4200000,\t4200000,\t4200000,\t4200000,\t4200000,\t4200000,\t4200000,\t4200000,\t4200000,\t4200000,\t4200000,\t4193000,\t4193000,\t4165000,\t4165000,\t4165000,\t4130000,\t4130000,\t4123000,\t4098500,\t4095000,\t4095000,\t4095000,\t4060000,\t4060000,\t4060000,\t4060000,\t4060000,\t4025000,\t4025000,\t4025000,\t4007500,\t4007500,\t3990000,\t3990000,\t3990000,\t3990000,\t3990000,\t3920000,\t3920000,\t3920000,\t3920000,\t3920000,\t3920000,\t3920000,\t3885000,\t3885000,\t3850000,\t3850000,\t3850000,\t3850000,\t3850000,\t3850000,\t3850000,\t3836000,\t3815000,\t3780000,\t3780000,\t3780000,\t3780000,\t3780000,\t3780000,\t3773000,\t3773000,\t3773000,\t3745000,\t3710000,\t3710000,\t3710000,\t3710000,\t3710000,\t3703000,\t3703000,\t3675000,\t3675000,\t3675000,\t3675000,\t3640000,\t3640000,\t3640000,\t3640000,\t3640000,\t3640000,\t3640000,\t3640000,\t3640000,\t3633000,\t3605000,\t3605000,\t3570000,\t3570000,\t3570000,\t3570000,\t3535000,\t3500000,\t3500000,\t3500000,\t3500000,\t3500000,\t3500000,\t3500000,\t3500000,\t3500000,\t3500000,\t3500000,\t3500000,\t3500000,\t3500000,\t3500000,\t3500000,\t3500000,\t3493000,\t3465000,\t3465000,\t3465000,\t3430000,\t3430000,\t3430000,\t3430000,\t3430000,\t3430000,\t3423000,\t3395000,\t3395000,\t3395000,\t3360000,\t3360000,\t3360000,\t3360000,\t3360000,\t3360000,\t3360000,\t3360000,\t3353000,\t3332000,\t3325000,\t3325000,\t3290000,\t3290000,\t3290000,\t3290000,\t3290000,\t3290000,\t3290000,\t3290000,\t3255000,\t3255000,\t3234000,\t3220000,\t3220000,\t3220000,\t3220000,\t3150000,\t3150000,\t3150000,\t3150000,\t3150000,\t3150000,\t3150000,\t3150000,\t3150000,\t3143000,\t3129000,\t3118850,\t3115000,\t3115000,\t3115000,\t3087000,\t3080000,\t3080000,\t3080000,\t3080000,\t3045000,\t3010000,\t3010000,\t3010000,\t3010000,\t3010000,\t3010000,\t3010000,\t3003000,\t2975000,\t2961000,\t2940000,\t2940000,\t2940000,\t2940000,\t2940000,\t2940000,\t2940000,\t2940000,\t2870000,\t2870000,\t2870000,\t2870000,\t2852500,\t2835000,\t2835000,\t2835000,\t2800000,\t2800000,\t2730000,\t2730000,\t2695000,\t2660000,\t2660000,\t2660000,\t2660000,\t2660000,\t2660000,\t2660000,\t2653000,\t2653000,\t2604000,\t2590000,\t2590000,\t2590000,\t2520000,\t2520000,\t2520000,\t2485000,\t2485000,\t2450000,\t2450000,\t2450000,\t2450000,\t2450000,\t2450000,\t2408000,\t2380000,\t2380000,\t2380000,\t2345000,\t2310000,\t2275000,\t2275000,\t2275000,\t2240000,\t2233000,\t2135000,\t2100000,\t2100000,\t2100000,\t1960000,\t1890000,\t1890000,\t1855000,\t1820000,\t1767150,\t1750000,\t1750000,\t1750000],\n",
        "    'area': [7420,\t8960,\t9960,\t7500,\t7420,\t7500,\t8580,\t16200,\t8100,\t5750,\t13200,\t6000,\t6550,\t3500,\t7800,\t6000,\t6600,\t8500,\t4600,\t6420,\t4320,\t7155,\t8050,\t4560,\t8800,\t6540,\t6000,\t8875,\t7950,\t5500,\t7475,\t7000,\t4880,\t5960,\t6840,\t7000,\t7482,\t9000,\t6000,\t6000,\t6550,\t6360,\t6480,\t6000,\t6000,\t6000,\t6000,\t6600,\t4300,\t7440,\t7440,\t6325,\t6000,\t5150,\t6000,\t6000,\t11440,\t9000,\t7680,\t6000,\t6000,\t8880,\t6240,\t6360,\t11175,\t8880,\t13200,\t7700,\t6000,\t12090,\t4000,\t6000,\t5020,\t6600,\t4040,\t4260,\t6420,\t6500,\t5700,\t6000,\t6000,\t4000,\t10500,\t6000,\t3760,\t8250,\t6670,\t3960,\t7410,\t8580,\t5000,\t6750,\t4800,\t7200,\t6000,\t4100,\t9000,\t6400,\t6600,\t6000,\t6600,\t5500,\t5500,\t6350,\t5500,\t4500,\t5450,\t6420,\t3240,\t6615,\t6600,\t8372,\t4300,\t9620,\t6800,\t8000,\t6900,\t3700,\t6420,\t7020,\t6540,\t7231,\t6254,\t7320,\t6525,\t15600,\t7160,\t6500,\t5500,\t11460,\t4800,\t5828,\t5200,\t4800,\t7000,\t6000,\t5400,\t4640,\t5000,\t6360,\t5800,\t6660,\t10500,\t4800,\t4700,\t5000,\t10500,\t5500,\t6360,\t6600,\t5136,\t4400,\t5400,\t3300,\t3650,\t6100,\t6900,\t2817,\t7980,\t3150,\t6210,\t6100,\t6600,\t6825,\t6710,\t6450,\t7800,\t4600,\t4260,\t6540,\t5500,\t10269,\t8400,\t5300,\t3800,\t9800,\t8520,\t6050,\t7085,\t3180,\t4500,\t7200,\t3410,\t7980,\t3000,\t3000,\t11410,\t6100,\t5720,\t3540,\t7600,\t10700,\t6600,\t4800,\t8150,\t4410,\t7686,\t2800,\t5948,\t4200,\t4520,\t4095,\t4120,\t5400,\t4770,\t6300,\t5800,\t3000,\t2970,\t6720,\t4646,\t12900,\t3420,\t4995,\t4350,\t4160,\t6040,\t6862,\t4815,\t7000,\t8100,\t3420,\t9166,\t6321,\t10240,\t6440,\t5170,\t6000,\t3630,\t9667,\t5400,\t4320,\t3745,\t4160,\t3880,\t5680,\t2870,\t5010,\t4510,\t4000,\t3840,\t3760,\t3640,\t2550,\t5320,\t5360,\t3520,\t8400,\t4100,\t4990,\t3510,\t3450,\t9860,\t3520,\t4510,\t5885,\t4000,\t8250,\t4040,\t6360,\t3162,\t3510,\t3750,\t3968,\t4900,\t2880,\t4880,\t4920,\t4950,\t3900,\t4500,\t1905,\t4075,\t3500,\t6450,\t4032,\t4400,\t10360,\t3400,\t6360,\t6360,\t4500,\t2175,\t4360,\t7770,\t6650,\t2787,\t5500,\t5040,\t5850,\t2610,\t2953,\t2747,\t4410,\t4000,\t2325,\t4600,\t3640,\t5800,\t7000,\t4079,\t3520,\t2145,\t4500,\t8250,\t3450,\t4840,\t4080,\t4046,\t4632,\t5985,\t6060,\t3600,\t3680,\t4040,\t5600,\t5900,\t4992,\t4340,\t3000,\t4320,\t3630,\t3460,\t5400,\t4500,\t3460,\t4100,\t6480,\t4500,\t3960,\t4050,\t7260,\t5500,\t3000,\t3290,\t3816,\t8080,\t2145,\t3780,\t3180,\t5300,\t3180,\t7152,\t4080,\t3850,\t2015,\t2176,\t3350,\t3150,\t4820,\t3420,\t3600,\t5830,\t2856,\t8400,\t8250,\t2520,\t6930,\t3480,\t3600,\t4040,\t6020,\t4050,\t3584,\t3120,\t5450,\t3630,\t3630,\t5640,\t3600,\t4280,\t3570,\t3180,\t3000,\t3520,\t5960,\t4130,\t2850,\t2275,\t3520,\t4500,\t4000,\t3150,\t4500,\t4500,\t3640,\t3850,\t4240,\t3650,\t4600,\t2135,\t3036,\t3990,\t7424,\t3480,\t3600,\t3640,\t5900,\t3120,\t7350,\t3512,\t9500,\t5880,\t12944,\t4900,\t3060,\t5320,\t2145,\t4000,\t3185,\t3850,\t2145,\t2610,\t1950,\t4040,\t4785,\t3450,\t3640,\t3500,\t4960,\t4120,\t4750,\t3720,\t3750,\t3100,\t3185,\t2700,\t2145,\t4040,\t4775,\t2500,\t3180,\t6060,\t3480,\t3792,\t4040,\t2145,\t5880,\t4500,\t3930,\t3640,\t4370,\t2684,\t4320,\t3120,\t3450,\t3986,\t3500,\t4095,\t1650,\t3450,\t6750,\t9000,\t3069,\t4500,\t5495,\t2398,\t3000,\t3850,\t3500,\t8100,\t4960,\t2160,\t3090,\t4500,\t3800,\t3090,\t3240,\t2835,\t4600,\t5076,\t3750,\t3630,\t8050,\t4352,\t3000,\t5850,\t4960,\t3600,\t3660,\t3480,\t2700,\t3150,\t6615,\t3040,\t3630,\t6000,\t5400,\t5200,\t3300,\t4350,\t2640,\t2650,\t3960,\t6800,\t4000,\t4000,\t3934,\t2000,\t3630,\t2800,\t2430,\t3480,\t4000,\t3185,\t4000,\t2910,\t3600,\t4400,\t3600,\t2880,\t3180,\t3000,\t4400,\t3000,\t3210,\t3240,\t3000,\t3500,\t4840,\t7700,\t3635,\t2475,\t2787,\t3264,\t3640,\t3180,\t1836,\t3970,\t3970,\t1950,\t5300,\t3000,\t2400,\t3000,\t3360,\t3420,\t1700,\t3649,\t2990,\t3000,\t2400,\t3620,\t2910,\t3850],\n",
        "    'bedrooms': [4,\t4,\t3,\t4,\t4,\t3,\t4,\t5,\t4,\t3,\t3,\t4,\t4,\t4,\t3,\t4,\t4,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t4,\t3,\t3,\t5,\t4,\t3,\t3,\t4,\t3,\t5,\t3,\t3,\t4,\t3,\t4,\t3,\t3,\t3,\t4,\t4,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t4,\t3,\t3,\t3,\t4,\t4,\t4,\t3,\t3,\t2,\t4,\t4,\t3,\t3,\t2,\t3,\t3,\t4,\t3,\t4,\t3,\t2,\t3,\t4,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t5,\t3,\t2,\t3,\t3,\t4,\t3,\t3,\t3,\t3,\t4,\t3,\t3,\t3,\t3,\t3,\t3,\t4,\t3,\t4,\t4,\t3,\t3,\t6,\t3,\t2,\t3,\t3,\t4,\t3,\t3,\t3,\t3,\t4,\t4,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t4,\t3,\t3,\t3,\t3,\t4,\t4,\t3,\t3,\t3,\t4,\t4,\t5,\t4,\t3,\t2,\t3,\t3,\t4,\t3,\t4,\t5,\t3,\t3,\t3,\t3,\t4,\t3,\t3,\t4,\t3,\t4,\t3,\t3,\t3,\t3,\t2,\t4,\t4,\t3,\t3,\t3,\t4,\t3,\t4,\t3,\t3,\t3,\t3,\t4,\t3,\t3,\t3,\t3,\t3,\t2,\t3,\t2,\t2,\t4,\t3,\t3,\t2,\t3,\t4,\t3,\t3,\t3,\t3,\t3,\t3,\t2,\t4,\t3,\t3,\t2,\t3,\t3,\t3,\t3,\t3,\t4,\t4,\t2,\t3,\t3,\t3,\t2,\t3,\t4,\t4,\t2,\t3,\t2,\t2,\t3,\t2,\t3,\t4,\t2,\t3,\t3,\t3,\t3,\t3,\t2,\t3,\t4,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t4,\t2,\t4,\t3,\t3,\t3,\t2,\t4,\t2,\t3,\t3,\t3,\t2,\t3,\t3,\t2,\t3,\t2,\t3,\t3,\t3,\t4,\t3,\t3,\t5,\t3,\t4,\t4,\t2,\t2,\t2,\t3,\t2,\t2,\t2,\t3,\t4,\t2,\t3,\t3,\t3,\t3,\t2,\t4,\t3,\t4,\t2,\t4,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t3,\t4,\t3,\t2,\t3,\t3,\t2,\t2,\t4,\t3,\t3,\t4,\t3,\t3,\t3,\t3,\t3,\t4,\t4,\t3,\t3,\t3,\t2,\t3,\t4,\t3,\t2,\t2,\t3,\t4,\t2,\t4,\t5,\t2,\t3,\t2,\t2,\t3,\t2,\t3,\t2,\t3,\t2,\t2,\t2,\t3,\t2,\t3,\t5,\t4,\t2,\t3,\t2,\t3,\t2,\t2,\t3,\t2,\t2,\t2,\t2,\t2,\t2,\t3,\t3,\t2,\t2,\t3,\t3,\t3,\t3,\t3,\t2,\t2,\t3,\t4,\t2,\t2,\t3,\t3,\t3,\t4,\t3,\t3,\t3,\t3,\t3,\t6,\t2,\t2,\t3,\t2,\t2,\t3,\t2,\t3,\t3,\t3,\t2,\t3,\t2,\t2,\t3,\t3,\t3,\t3,\t2,\t3,\t3,\t2,\t4,\t4,\t2,\t2,\t2,\t3,\t3,\t2,\t3,\t3,\t2,\t4,\t2,\t4,\t3,\t4,\t4,\t2,\t3,\t3,\t2,\t2,\t4,\t3,\t2,\t3,\t3,\t1,\t2,\t2,\t2,\t3,\t3,\t2,\t3,\t2,\t3,\t3,\t3,\t3,\t3,\t2,\t2,\t2,\t3,\t2,\t2,\t2,\t3,\t3,\t2,\t2,\t3,\t3,\t4,\t2,\t4,\t2,\t3,\t2,\t3,\t4,\t3,\t2,\t3,\t3,\t2,\t2,\t2,\t4,\t4,\t3,\t3,\t2,\t3,\t3,\t2,\t3,\t2,\t2,\t2,\t3,\t3,\t3,\t2,\t3,\t2,\t3,\t2,\t2,\t2,\t2,\t3,\t3,\t2,\t3,\t3,\t3,\t2,\t2,\t2,\t2,\t2,\t2,\t3,\t4,\t2,\t2,\t2,\t2,\t1,\t3,\t3,\t3,\t2,\t3,\t4,\t2,\t5,\t3,\t2,\t2,\t2,\t3,\t2,\t3,\t3],\n",
        "    'bathrooms': [2,\t4,\t2,\t2,\t1,\t3,\t3,\t3,\t1,\t2,\t1,\t3,\t2,\t2,\t2,\t1,\t2,\t2,\t2,\t2,\t1,\t2,\t1,\t2,\t2,\t2,\t2,\t1,\t2,\t2,\t2,\t1,\t2,\t3,\t1,\t2,\t2,\t2,\t1,\t2,\t1,\t2,\t2,\t2,\t2,\t2,\t2,\t1,\t2,\t2,\t2,\t1,\t2,\t2,\t2,\t1,\t1,\t2,\t2,\t2,\t2,\t1,\t2,\t2,\t1,\t2,\t1,\t2,\t1,\t2,\t2,\t2,\t1,\t2,\t1,\t2,\t2,\t2,\t1,\t2,\t1,\t2,\t2,\t2,\t1,\t2,\t1,\t1,\t1,\t3,\t1,\t1,\t2,\t2,\t2,\t2,\t1,\t1,\t2,\t1,\t2,\t1,\t2,\t2,\t2,\t1,\t2,\t1,\t1,\t2,\t1,\t1,\t2,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t2,\t2,\t2,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t2,\t1,\t1,\t1,\t2,\t2,\t2,\t2,\t1,\t1,\t1,\t2,\t1,\t2,\t1,\t1,\t1,\t3,\t2,\t2,\t1,\t2,\t1,\t2,\t1,\t1,\t2,\t1,\t2,\t2,\t1,\t2,\t1,\t2,\t2,\t1,\t1,\t2,\t1,\t2,\t1,\t1,\t1,\t2,\t2,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t3,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t3,\t1,\t2,\t1,\t2,\t1,\t2,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t2,\t2,\t1,\t1,\t1,\t2,\t2,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t2,\t2,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t2,\t2,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t3,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1],\n",
        "    'stories': [3,\t4,\t2,\t2,\t2,\t1,\t4,\t2,\t2,\t4,\t2,\t2,\t2,\t2,\t2,\t2,\t2,\t4,\t2,\t2,\t2,\t1,\t1,\t2,\t2,\t2,\t4,\t1,\t2,\t2,\t4,\t4,\t2,\t2,\t2,\t4,\t3,\t4,\t4,\t4,\t2,\t4,\t4,\t4,\t4,\t3,\t4,\t4,\t2,\t1,\t4,\t4,\t4,\t4,\t2,\t2,\t2,\t4,\t4,\t4,\t2,\t1,\t2,\t3,\t1,\t2,\t1,\t1,\t1,\t2,\t2,\t4,\t4,\t4,\t2,\t2,\t3,\t3,\t1,\t3,\t2,\t2,\t1,\t4,\t2,\t3,\t3,\t1,\t1,\t2,\t2,\t1,\t4,\t1,\t4,\t3,\t1,\t1,\t3,\t3,\t1,\t3,\t4,\t3,\t1,\t4,\t1,\t3,\t3,\t2,\t1,\t3,\t2,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t2,\t1,\t2,\t4,\t1,\t1,\t3,\t3,\t3,\t1,\t4,\t3,\t3,\t1,\t4,\t2,\t2,\t3,\t1,\t4,\t2,\t2,\t3,\t2,\t4,\t1,\t2,\t3,\t1,\t2,\t2,\t2,\t2,\t2,\t1,\t1,\t2,\t1,\t1,\t4,\t3,\t2,\t1,\t2,\t1,\t1,\t1,\t2,\t2,\t1,\t1,\t2,\t1,\t2,\t2,\t1,\t1,\t1,\t2,\t1,\t2,\t2,\t1,\t2,\t2,\t2,\t1,\t2,\t1,\t2,\t2,\t1,\t1,\t1,\t2,\t1,\t2,\t2,\t2,\t2,\t2,\t1,\t2,\t1,\t1,\t1,\t2,\t3,\t1,\t2,\t1,\t2,\t1,\t1,\t3,\t1,\t2,\t1,\t2,\t4,\t2,\t1,\t2,\t1,\t1,\t4,\t1,\t2,\t2,\t2,\t1,\t2,\t1,\t2,\t2,\t2,\t2,\t2,\t2,\t2,\t1,\t2,\t2,\t2,\t2,\t1,\t4,\t1,\t2,\t3,\t2,\t1,\t2,\t2,\t1,\t2,\t1,\t2,\t1,\t2,\t2,\t1,\t2,\t2,\t2,\t1,\t2,\t2,\t2,\t3,\t2,\t1,\t2,\t2,\t1,\t1,\t1,\t2,\t1,\t2,\t1,\t2,\t2,\t1,\t2,\t1,\t2,\t2,\t1,\t2,\t2,\t2,\t1,\t2,\t2,\t2,\t2,\t1,\t1,\t3,\t2,\t3,\t1,\t1,\t2,\t2,\t2,\t2,\t2,\t1,\t1,\t1,\t2,\t2,\t1,\t2,\t2,\t1,\t3,\t2,\t2,\t1,\t1,\t2,\t2,\t1,\t2,\t2,\t2,\t2,\t1,\t2,\t2,\t1,\t1,\t1,\t1,\t2,\t2,\t2,\t1,\t2,\t1,\t1,\t2,\t2,\t2,\t1,\t2,\t2,\t1,\t1,\t3,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t2,\t2,\t1,\t2,\t2,\t2,\t3,\t1,\t1,\t1,\t2,\t2,\t1,\t1,\t1,\t2,\t2,\t2,\t2,\t2,\t2,\t1,\t1,\t2,\t1,\t1,\t2,\t1,\t1,\t2,\t1,\t1,\t2,\t1,\t1,\t3,\t1,\t1,\t1,\t3,\t2,\t2,\t1,\t2,\t1,\t1,\t2,\t3,\t2,\t1,\t1,\t1,\t2,\t1,\t1,\t2,\t1,\t2,\t1,\t2,\t1,\t2,\t2,\t1,\t2,\t1,\t1,\t1,\t2,\t2,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t2,\t2,\t1,\t2,\t1,\t2,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t2,\t1,\t2,\t1,\t2,\t2,\t1,\t1,\t1,\t2,\t2,\t1,\t2,\t2,\t2,\t1,\t2,\t2,\t2,\t1,\t2,\t2,\t1,\t1,\t1,\t2,\t3,\t2,\t2,\t1,\t2,\t1,\t1,\t2,\t1,\t1,\t2,\t2,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t2,\t1,\t1,\t2,\t2,\t2,\t2,\t1,\t1,\t1,\t2,\t1,\t1,\t2,\t2,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t2,\t2,\t1,\t2,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t2],\n",
        "    'parking': [2,\t3,\t2,\t3,\t2,\t2,\t2,\t0,\t2,\t1,\t2,\t2,\t1,\t2,\t0,\t2,\t1,\t2,\t2,\t1,\t2,\t2,\t1,\t1,\t2,\t2,\t0,\t1,\t2,\t1,\t2,\t2,\t1,\t1,\t1,\t2,\t1,\t2,\t2,\t1,\t0,\t0,\t2,\t2,\t1,\t0,\t1,\t3,\t1,\t0,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t2,\t1,\t1,\t1,\t2,\t1,\t2,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t2,\t0,\t1,\t1,\t1,\t0,\t2,\t0,\t0,\t2,\t2,\t2,\t0,\t2,\t0,\t3,\t1,\t2,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t2,\t0,\t0,\t0,\t1,\t1,\t2,\t2,\t0,\t2,\t2,\t2,\t0,\t0,\t0,\t2,\t2,\t0,\t1,\t0,\t1,\t2,\t2,\t0,\t1,\t2,\t0,\t0,\t0,\t0,\t2,\t0,\t2,\t1,\t0,\t2,\t0,\t1,\t1,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t2,\t0,\t0,\t2,\t2,\t0,\t1,\t2,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t2,\t2,\t0,\t0,\t0,\t1,\t2,\t0,\t1,\t2,\t2,\t0,\t2,\t2,\t2,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t2,\t0,\t0,\t0,\t0,\t2,\t0,\t1,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t2,\t0,\t0,\t0,\t0,\t2,\t2,\t2,\t0,\t0,\t0,\t2,\t2,\t0,\t0,\t2,\t0,\t2,\t1,\t2,\t3,\t0,\t1,\t2,\t1,\t0,\t0,\t0,\t0,\t2,\t1,\t0,\t0,\t0,\t1,\t1,\t2,\t0,\t0,\t0,\t2,\t0,\t3,\t0,\t0,\t0,\t1,\t0,\t0,\t2,\t1,\t2,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t2,\t1,\t0,\t0,\t1,\t0,\t2,\t2,\t0,\t0,\t1,\t1,\t2,\t0,\t0,\t2,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t2,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t2,\t3,\t0,\t0,\t1,\t0,\t3,\t1,\t1,\t2,\t1,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t1,\t2,\t0,\t2,\t2,\t2,\t1,\t3,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t3,\t0,\t0,\t1,\t2,\t2,\t0,\t0,\t0,\t0,\t2,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t2,\t0,\t1,\t2,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t2,\t0,\t0,\t0,\t0,\t0,\t2,\t0,\t0,\t2,\t0,\t0,\t0,\t2,\t0,\t0,\t2,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t3,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t2,\t0,\t0,\t0,\t0,\t0,\t1,\t2,\t0,\t2,\t0,\t0,\t0,\t0,\t0,\t0,\t2,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t2,\t0,\t0,\t0,\t2,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t2,\t0,\t0,\t0,\t0,\t3,\t0,\t1,\t0,\t1,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t2,\t0,\t0,\t0,\t0],\n",
        "    'mainroad': [1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t0,\t1,\t0,\t1,\t0,\t1,\t1,\t1,\t0,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t0,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t0,\t1,\t1,\t0,\t1,\t0,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t1,\t1,\t0,\t1,\t0,\t1,\t0,\t1],\n",
        "    'guestroom': [0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t1,\t1,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t1,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0],\n",
        "    'basement': [0,\t0,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t1,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t0,\t1,\t0,\t1,\t0,\t1,\t0,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t0,\t1,\t1,\t0,\t1,\t0,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t1,\t1,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t1,\t0,\t1,\t0,\t1,\t0,\t1,\t1,\t1,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0],\n",
        "    'hotwaterheating': [0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0],\n",
        "    'aircondition': [1,\t1,\t0,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t0,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t1,\t0,\t0,\t1,\t0,\t1,\t0,\t1,\t1,\t0,\t1,\t0,\t1,\t1,\t0,\t1,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t1,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t1,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0],\n",
        "    'prefarea': [1,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t1,\t1,\t1,\t0,\t1,\t0,\t1,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t1,\t1,\t0,\t0,\t1,\t1,\t1,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t1,\t1,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t1,\t0,\t0,\t1,\t1,\t0,\t0,\t1,\t0,\t1,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t1,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t0,\t1,\t1,\t0,\t0,\t0,\t1,\t1,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0],\n",
        "    })\n",
        "\n",
        "# Define input features and target variable\n",
        "X = data[['area', 'bedrooms', 'bathrooms', 'stories', 'parking', 'mainroad', 'guestroom', 'basement', 'hotwaterheating', 'aircondition', 'prefarea']].values  # Convert to NumPy array\n",
        "y = data['price'].values\n",
        "\n",
        "# Split the data into training and validation sets (80% - 20% split)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the input features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "\n",
        "# Function to create and train a linear regression model\n",
        "def train_linear_regression(X_train, y_train, X_val, y_val, optimizer, learning_rate, epochs):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Input(shape=(11,)),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer=optimizer(learning_rate=learning_rate), loss='mean_squared_error')\n",
        "\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, verbose=0)\n",
        "    return model, history.history\n",
        "\n",
        "# Hyperparameters to explore\n",
        "learning_rates = [0.1, 0.01, 0.001, 0.0001]\n",
        "epochs = 5500\n",
        "report_interval = 500\n",
        "\n",
        "# Train models with different learning rates using both SGD and ADAM optimizers\n",
        "results = []\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for optimizer_name, optimizer in [('SGD', tf.optimizers.SGD), ('ADAM', tf.optimizers.Adam)]:\n",
        "        model, history = train_linear_regression(X_train, y_train, X_val, y_val, optimizer, lr, epochs)\n",
        "\n",
        "        # Print loss and validation accuracy for every 500 epochs\n",
        "        for epoch in range(500, epochs, report_interval):\n",
        "            loss = history['loss'][epoch]\n",
        "            val_loss = history['val_loss'][epoch]\n",
        "            print(f\"Optimizer: {optimizer_name}, Learning Rate: {lr}, Epoch: {epoch}, Loss: {loss}, Validation Loss: {val_loss}\")\n",
        "\n",
        "        results.append((optimizer_name, lr, history['val_loss'][-1]))\n",
        "\n",
        "# Find the best model\n",
        "best_result = min(results, key=lambda x: x[2])\n",
        "best_optimizer, best_lr, best_val_loss = best_result\n",
        "print(f\"Best model: Optimizer = {best_optimizer}, Learning Rate = {best_lr}, Validation Loss = {best_val_loss}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKmjZAGwpS8O",
        "outputId": "baae4e6d-e5f2-4930-d2dc-a0d6f037120d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 500, Loss: 1076676853760.0, Validation Loss: 1798305087488.0\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 1000, Loss: 1098932486144.0, Validation Loss: 1655891820544.0\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 1500, Loss: 1064145780736.0, Validation Loss: 1859118432256.0\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 2000, Loss: 1108242202624.0, Validation Loss: 1798743523328.0\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 2500, Loss: 1057548795904.0, Validation Loss: 1813929787392.0\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 3000, Loss: 1051559657472.0, Validation Loss: 1768246738944.0\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 3500, Loss: 1058839592960.0, Validation Loss: 1957868601344.0\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 4000, Loss: 1073080631296.0, Validation Loss: 1819764850688.0\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 4500, Loss: 1121833320448.0, Validation Loss: 1956794597376.0\n",
            "Optimizer: SGD, Learning Rate: 0.1, Epoch: 5000, Loss: 1045941583872.0, Validation Loss: 1970773819392.0\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 500, Loss: 25222828785664.0, Validation Loss: 30113959772160.0\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 1000, Loss: 25210902282240.0, Validation Loss: 30097981571072.0\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 1500, Loss: 25198992556032.0, Validation Loss: 30082030632960.0\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 2000, Loss: 25187074441216.0, Validation Loss: 30066069209088.0\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 2500, Loss: 25175191977984.0, Validation Loss: 30050158116864.0\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 3000, Loss: 25163299028992.0, Validation Loss: 30034228150272.0\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 3500, Loss: 25151445925888.0, Validation Loss: 30018359001088.0\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 4000, Loss: 25139584434176.0, Validation Loss: 30002462588928.0\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 4500, Loss: 25127748108288.0, Validation Loss: 29986616508416.0\n",
            "Optimizer: ADAM, Learning Rate: 0.1, Epoch: 5000, Loss: 25115909685248.0, Validation Loss: 29970747359232.0\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 500, Loss: 1001191964672.0, Validation Loss: 1790107713536.0\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 1000, Loss: 1000705490944.0, Validation Loss: 1786621853696.0\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 1500, Loss: 999847493632.0, Validation Loss: 1801906683904.0\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 2000, Loss: 1000595914752.0, Validation Loss: 1796020764672.0\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 2500, Loss: 1002162814976.0, Validation Loss: 1816334958592.0\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 3000, Loss: 1000364441600.0, Validation Loss: 1806633533440.0\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 3500, Loss: 999679655936.0, Validation Loss: 1801512812544.0\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 4000, Loss: 1002369646592.0, Validation Loss: 1799034241024.0\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 4500, Loss: 998723289088.0, Validation Loss: 1801863430144.0\n",
            "Optimizer: SGD, Learning Rate: 0.01, Epoch: 5000, Loss: 1001043656704.0, Validation Loss: 1797047582720.0\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 500, Loss: 25233597661184.0, Validation Loss: 30128394469376.0\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 1000, Loss: 25232400187392.0, Validation Loss: 30126794342400.0\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 1500, Loss: 25231204810752.0, Validation Loss: 30125192118272.0\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 2000, Loss: 25230011531264.0, Validation Loss: 30123591991296.0\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 2500, Loss: 25228818251776.0, Validation Loss: 30121991864320.0\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 3000, Loss: 25227620777984.0, Validation Loss: 30120385445888.0\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 3500, Loss: 25226429595648.0, Validation Loss: 30118787416064.0\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 4000, Loss: 25225230024704.0, Validation Loss: 30117187289088.0\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 4500, Loss: 25224036745216.0, Validation Loss: 30115585064960.0\n",
            "Optimizer: ADAM, Learning Rate: 0.01, Epoch: 5000, Loss: 25222841368576.0, Validation Loss: 30113984937984.0\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 500, Loss: 993121206272.0, Validation Loss: 1799930642432.0\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 1000, Loss: 993364344832.0, Validation Loss: 1801353691136.0\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 1500, Loss: 993299922944.0, Validation Loss: 1801256042496.0\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 2000, Loss: 993648246784.0, Validation Loss: 1801212657664.0\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 2500, Loss: 993394556928.0, Validation Loss: 1800372617216.0\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 3000, Loss: 993295990784.0, Validation Loss: 1800231583744.0\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 3500, Loss: 993484800000.0, Validation Loss: 1799858290688.0\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 4000, Loss: 993262239744.0, Validation Loss: 1799725776896.0\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 4500, Loss: 993365196800.0, Validation Loss: 1801359065088.0\n",
            "Optimizer: SGD, Learning Rate: 0.001, Epoch: 5000, Loss: 993341603840.0, Validation Loss: 1801006743552.0\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 500, Loss: 25234669305856.0, Validation Loss: 30129833115648.0\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 1000, Loss: 25234553962496.0, Validation Loss: 30129675829248.0\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 1500, Loss: 25234432327680.0, Validation Loss: 30129516445696.0\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 2000, Loss: 25234314887168.0, Validation Loss: 30129354964992.0\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 2500, Loss: 25234195349504.0, Validation Loss: 30129195581440.0\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 3000, Loss: 25234075811840.0, Validation Loss: 30129032003584.0\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 3500, Loss: 25233958371328.0, Validation Loss: 30128874717184.0\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 4000, Loss: 25233836736512.0, Validation Loss: 30128715333632.0\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 4500, Loss: 25233715101696.0, Validation Loss: 30128553852928.0\n",
            "Optimizer: ADAM, Learning Rate: 0.001, Epoch: 5000, Loss: 25233597661184.0, Validation Loss: 30128394469376.0\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 500, Loss: 2362620248064.0, Validation Loss: 3494136774656.0\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 1000, Loss: 1079265198080.0, Validation Loss: 1940942618624.0\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 1500, Loss: 998747930624.0, Validation Loss: 1813968322560.0\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 2000, Loss: 993230520320.0, Validation Loss: 1801057337344.0\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 2500, Loss: 992679231488.0, Validation Loss: 1799953186816.0\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 3000, Loss: 992597770240.0, Validation Loss: 1799212367872.0\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 3500, Loss: 992581976064.0, Validation Loss: 1799624589312.0\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 4000, Loss: 992572145664.0, Validation Loss: 1800974368768.0\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 4500, Loss: 992573915136.0, Validation Loss: 1801043968000.0\n",
            "Optimizer: SGD, Learning Rate: 0.0001, Epoch: 5000, Loss: 992559169536.0, Validation Loss: 1800655994880.0\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 500, Loss: 25234780454912.0, Validation Loss: 30129977819136.0\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 1000, Loss: 25234767872000.0, Validation Loss: 30129963139072.0\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 1500, Loss: 25234759483392.0, Validation Loss: 30129946361856.0\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 2000, Loss: 25234744803328.0, Validation Loss: 30129929584640.0\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 2500, Loss: 25234736414720.0, Validation Loss: 30129914904576.0\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 3000, Loss: 25234717540352.0, Validation Loss: 30129898127360.0\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 3500, Loss: 25234711248896.0, Validation Loss: 30129883447296.0\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 4000, Loss: 25234696568832.0, Validation Loss: 30129868767232.0\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 4500, Loss: 25234686083072.0, Validation Loss: 30129849892864.0\n",
            "Optimizer: ADAM, Learning Rate: 0.0001, Epoch: 5000, Loss: 25234673500160.0, Validation Loss: 30129835212800.0\n",
            "Best model: Optimizer = SGD, Learning Rate = 0.1, Validation Loss = 1671607091200.0\n"
          ]
        }
      ]
    }
  ]
}